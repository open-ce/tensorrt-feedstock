{% set tensorrt_version = "7.2.3.4" %}
{% set sha256 = "ac07228bfd07f2fc3b9cb0b0f53f48af7537ad69399c4bdc69d7dcfe3fb85df9" %}   #[(x86_64) and (cudatoolkit == '11.0')]
{% set trt_tar = "TensorRT-7.2.3.4.CentOS-7.9.x86_64-gnu.cuda-11.0.cudnn8.1.tar.gz" %}  #[(x86_64) and (cudatoolkit == '11.0')]
{% set sha256 = "95b50a53e4a36be14aff9bf7bb6eab0858933b03e0f8c5949dfe2265a6ce9969" %}   #[(x86_64) and (cudatoolkit == '11.2')]
{% set trt_tar = "TensorRT-7.2.3.4.CentOS-7.9.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz" %}  #[(x86_64) and (cudatoolkit == '11.2')]

{% set trt_tar_dir =  environ.get('LOCAL_SRC_DIR', 0) %}

package:
  name: tensorrt
  version: {{ tensorrt_version }}

source:
  - url: file:/{{ trt_tar_dir }}/{{ trt_tar }}
    sha256: {{ sha256 }}                        
    patches:
       # 02xx - GPU only patch specific to open-ce (maybe)
       - 0204-update-Makefile.conf-for-conda-builds.patch
       - 0205-update-default-data-path.patch

       # 03xx - patch temporary to fix a problem that when fixed upstream can be removed
       - 0303-fix-yolov3-for-py3x.patch 
    folder: tensorrt

  - git_url: "https://github.com/NVIDIA/TensorRT.git"
    git_tag: 21.06
    patches:
       # 02xx - GPU only patch specific to open-ce (maybe)
       - 0201-add-build-onnx2trt-flag.patch
       #- 0202-only-install-onnx2trt.patch
       - 0203-Fixed-samples-CMakeLists-for-conda-builds.patch

       # 03xx - patch temporary to fix a problem that when fixed upstream can be removed
       - 0301-fix-GLIBC_2.14-link-issue-with-libnvinfer.so.patch # [x86_64]
       - 0302-Fix-libcaffeparser-name-for-samples.patch
       - 0304-modified-print-function-syntax-as-per-py3.patch
       #- add-makefiles-for-new-samples.patch
    folder: TensorRT

build:
  number: 1
  string: h{{ PKG_HASH }}_cuda{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}
  script_env:
    - CUDA_HOME
  skip: True  #[ppc64le]

outputs:
   - name: tensorrt
     script: build-tensorrt.sh
     requirements:
         build:
           - {{ compiler('cxx') }}
           # Use pins to control cos6/cos7 match
           - libgcc-ng  {{ libgcc }}
           - libstdcxx-ng  {{ libstdcxx }}
           - cmake {{ cmake }}
           - make
         host:
           - python {{ python }}
           - protobuf {{ protobuf }}
           - libprotobuf {{ protobuf }}
           - cudnn {{ cudnn }}
           - libmemcpy_wrapper            #[x86_64]
           - libclock_gettime_wrapper     #[x86_64]
           # Use pins to control cos6/cos7 match
           - libgcc-ng  {{ libgcc }}
           - libstdcxx-ng  {{ libstdcxx }}

         run:
           - python {{ python }}
           - cudatoolkit {{ cudatoolkit }}
           - protobuf {{ protobuf }}
           - libprotobuf {{ protobuf }}
           - cudnn {{ cudnn }}
           - numpy {{ numpy }}
           - uff {{ uff }}
           - graphsurgeon {{ graphsurgeon }}
<<<<<<< HEAD:tensorrt7.2.3/tensorrt/meta.yaml
           - onnx-graphsurgeon {{ onnx_graphsurgeon }}
           - libmemcpy_wrapper            #[x86_64]
           - libclock_gettime_wrapper     #[x86_64]
=======

>>>>>>> 642598ec1b2042a53ea320607899861cd89379d3:tensorrt7.0/tensorrt/meta.yaml

   - name: tensorrt-samples
     script: build-tensorrt-samples.sh
     requirements:
         build:
           - {{ compiler('cxx') }}
           # Use pins to control cos6/cos7 match
           - libgcc-ng  {{ libgcc }}
           - libstdcxx-ng  {{ libstdcxx }}
           - cmake {{ cmake }}
           - make
         host:
           - python {{ python }}
           - protobuf {{ protobuf }}
           - libprotobuf {{ protobuf }}
           - cudnn {{ cudnn }}
           - tensorrt {{ tensorrt_version }}
           # Use pins to control cos6/cos7 match
           - libgcc-ng  {{ libgcc }}
           - libstdcxx-ng  {{ libstdcxx }}

         run:
           - decorator
           - pywget
           - tensorrt {{ tensorrt_version }}
           - python {{ python }}
           - onnx {{ onnx }}
           - pillow {{ pillow }}
           - requests {{ requests }}
           - cmake {{ cmake }}
           - make
           - numpy {{ numpy }}
           - gxx_linux-64       {{ cxx_compiler_version }} # [x86_64]
           - gxx_linux-ppc64le  {{ cxx_compiler_version }} # [ppc64le]

about:
  home: https://developer.nvidia.com/tensorrt
  license: NVIDIA Software License, Apache-2.0
  summary: TensorRT is a C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.
  description: |
    NVIDIA TensorRT is a platform for high-performance deep learning inference. 
    It includes a deep learning inference optimizer and runtime that delivers low 
    latency and high-throughput for deep learning inference applications.
  dev_url: https://github.com/NVIDIA/TensorRT/
  doc_url: https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
